{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.linalg\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 100\n",
    "n_train_max  = 1800  # this has to be larger than 4**n_qubits\n",
    "reps = 5\n",
    "\n",
    "qubits_list = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml(\"Fashion-MNIST\", version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "# map data in [0,1] range\n",
    "X = X / 255.0\n",
    "\n",
    "# split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=60000, test_size=10000)\n",
    "\n",
    "# standardize data -- make mean 0 and std 1\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# choose only two classes '0' and '1' for now\n",
    "train_filter = np.where((y_train == '0') | (y_train == '1'))\n",
    "test_filter = np.where((y_test == '0') | (y_test == '1'))\n",
    "\n",
    "# reduced training and test data with only 2 classes\n",
    "x_train_red, y_train_red = X_train[train_filter], y_train[train_filter]\n",
    "x_test_red, y_test_red = X_test[test_filter], y_test[test_filter]\n",
    "\n",
    "# Reshape labels to one-hot encode them\n",
    "y_train_red = y_train_red.reshape(-1, 1)\n",
    "y_test_red = y_test_red.reshape(-1, 1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(y_train_red)\n",
    "y_train = ohe.transform(y_train_red).toarray()\n",
    "ohe.fit(y_test_red)\n",
    "y_test = ohe.transform(y_test_red).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "for n_qubits in qubits_list:\n",
    "\n",
    "    import os\n",
    "\n",
    "    data_directory = f\"Data/{n_qubits}_qubits\"\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(f\"./{data_directory}\", exist_ok=True)\n",
    "\n",
    "    graph_directory = f\"Graphs/{n_qubits}_qubits\"\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(f\"./{graph_directory}\", exist_ok=True)\n",
    "\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "\n",
    "    def quantum_feature_map(x):\n",
    "        \"\"\"\n",
    "        Feature map for quantum kernel.\n",
    "        Adjust repetitions (reps) or gates if kernel is not full rank.\n",
    "        \"\"\"\n",
    "        reps = n_qubits\n",
    "        for r in range(reps):\n",
    "            for i in range(len(x)):\n",
    "                qml.RX(x[i], wires=i % n_qubits)\n",
    "            for n in range(n_qubits - 1):\n",
    "                qml.CNOT(wires=[n, n + 1])\n",
    "            for i in range(len(x)):\n",
    "                qml.RZ(x[i], wires=i % n_qubits)\n",
    "\n",
    "    dev_kernel = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "    @qml.qnode(dev_kernel)\n",
    "    def kernel_state(x1):\n",
    "        \"\"\"\n",
    "        Takes as input data and returns density matrix.\n",
    "        Use this function to generate rho(X).\n",
    "        \"\"\"\n",
    "        quantum_feature_map(x1)\n",
    "        return qml.density_matrix(wires=range(n_qubits))\n",
    "\n",
    "    projector = np.zeros((2 ** n_qubits, 2 ** n_qubits))\n",
    "    projector[0, 0] = 1\n",
    "\n",
    "    @qml.qnode(dev_kernel)\n",
    "    def kernel(x1, x2):\n",
    "        \"\"\"The quantum kernel.\"\"\"\n",
    "        quantum_feature_map(x1)\n",
    "        qml.adjoint(quantum_feature_map)(x2)\n",
    "        return qml.expval(qml.Hermitian(projector, wires=range(n_qubits)))\n",
    "\n",
    "    def kernel_matrix(A, B):\n",
    "        \"\"\"Compute the matrix whose entries are the kernel evaluated on pairwise data from sets A and B.\"\"\"\n",
    "        return np.array([[kernel(a, b) for b in B] for a in A])\n",
    "\n",
    "\n",
    "    # compute data matrix condition number and rank -------------------------------------------------------------------\n",
    "    @qml.qnode(dev_kernel)\n",
    "    def kernel_state(x1):\n",
    "        \"\"\"The quantum data encoding.\"\"\"\n",
    "        quantum_feature_map(x1)\n",
    "        return qml.density_matrix(wires=range(n_qubits))\n",
    "\n",
    "    def compute_rank(A, tol=None):\n",
    "        U, s, Vh = scipy.linalg.svd(A)\n",
    "        if tol is None:\n",
    "            tol = max(A.shape) * np.spacing(np.max(s))\n",
    "        rank = np.sum(s > tol)\n",
    "        return rank\n",
    "\n",
    "    \n",
    "    print(\"*-\"*20)\n",
    "    print(\"Number of qubits: \", n_qubits)\n",
    "\n",
    "    # Initialize PCA with the number of components\n",
    "    to_use = 2 * n_qubits\n",
    "    pca = PCA(n_components=to_use)\n",
    "\n",
    "    # Fit the PCA model and transform the data\n",
    "    x_train = pca.fit_transform(x_train_red)\n",
    "    x_test = pca.transform(x_test_red)\n",
    "\n",
    "    # choose only subset of data\n",
    "    x_test = x_test[:n_test]\n",
    "    y_test = y_test[:n_test]\n",
    "\n",
    "\n",
    "    mse_arr = [[] for _ in range(reps)]\n",
    "    mse_arr_train = [[] for _ in range(reps)]\n",
    "    eig_vals_arr = [[] for _ in range(reps)]\n",
    "    cond_no_arr = [[] for _ in range(reps)]\n",
    "    rank_arr = [[] for _ in range(reps)]\n",
    "    params = [[] for _ in range(reps)]\n",
    "    K_train_arr = []\n",
    "\n",
    "    for r in range(reps):\n",
    "\n",
    "        x_train_max = x_train[r * n_train_max:(r + 1) * n_train_max]\n",
    "        y_train_max = y_train[r * n_train_max:(r + 1) * n_train_max]\n",
    "\n",
    "        if n_qubits == 1:\n",
    "            limit_low, limit_up, step = 1, 8, 1\n",
    "        elif n_qubits == 2:\n",
    "            limit_low, limit_up, step = 2**(2 * n_qubits) - 10, 2**(2 * n_qubits) + 11, 2\n",
    "        elif n_qubits == 3:\n",
    "            limit_low, limit_up, step = 2**(2 * n_qubits) - 60, 2**(2 * n_qubits) + 61, 20\n",
    "        elif n_qubits == 4:\n",
    "            limit_low, limit_up, step = 2**(2 * n_qubits) - 180, 2**(2 * n_qubits) + 181, 60\n",
    "        elif n_qubits == 5:\n",
    "            limit_low, limit_up, step = 2**(2 * n_qubits) - 720, 2**(2 * n_qubits) + 721, 240\n",
    "\n",
    "        for n_train in range(limit_low, limit_up, step):\n",
    "            x_train_krr = x_train_max[:n_train]\n",
    "            y_train_krr = y_train_max[:n_train]\n",
    "            print(r + 1, \": train samples: \", x_train_krr.shape[0], \"/\", limit_up - 1)\n",
    "\n",
    "            K_train = kernel_matrix(x_train_krr, x_train_krr).astype(np.float64)\n",
    "            K_test = kernel_matrix(x_test, x_train_krr).astype(np.float64)\n",
    "            K_train_arr.append(K_train)\n",
    "\n",
    "            kernel_ridge_model = KernelRidge(kernel='precomputed', alpha=0.0)\n",
    "            kernel_ridge_model.fit(K_train, y_train_krr)\n",
    "\n",
    "            predictions = kernel_ridge_model.predict(K_test)\n",
    "            train_predictions = kernel_ridge_model.predict(K_train)\n",
    "\n",
    "            params[r].append(kernel_ridge_model.dual_coef_)\n",
    "\n",
    "            K_eig_vals = np.linalg.eig(K_train)[0]\n",
    "            cond_no = np.linalg.cond(K_train)\n",
    "            rank = np.linalg.matrix_rank(K_train)\n",
    "\n",
    "            eig_vals_arr[r].append(K_eig_vals)\n",
    "            cond_no_arr[r].append(cond_no)\n",
    "            rank_arr[r].append(rank)\n",
    "            print(\"Rank of Kernel: \", rank)\n",
    "\n",
    "            mse = mean_squared_error(np.real(y_test), predictions)\n",
    "            mse_arr[r].append(mse)\n",
    "            print(\"Mean Squared Error Test:\", mse)\n",
    "\n",
    "            train_mse = mean_squared_error(y_train_krr, train_predictions)\n",
    "            mse_arr_train[r].append(train_mse)\n",
    "            print(\"Mean Squared Error Train:\", train_mse)\n",
    "        \n",
    "\n",
    "    # compute data matrix condition number and rank -------------------------------------------------------------------\n",
    "    no_train = 2**(2*n_qubits)\n",
    "    cond_no_arr = []\n",
    "    rank_arr = []\n",
    "    for n in range(limit_low, limit_up, step):\n",
    "        X = [kernel_state(x_train_max[m, :]).flatten().astype(np.complex128) for m in range(n)]\n",
    "        cond_no = np.linalg.cond(X)\n",
    "        cond_no_arr.append(cond_no)\n",
    "        rank_arr.append(compute_rank(np.array(X)))\n",
    "\n",
    "\n",
    "    import pickle\n",
    "\n",
    "    # Creating a dictionary to store all the arrays\n",
    "    data = {\n",
    "        'mse_arr': mse_arr,\n",
    "        'mse_arr_train': mse_arr_train,\n",
    "        'eig_vals_arr': eig_vals_arr,\n",
    "        'cond_no_arr': cond_no_arr,\n",
    "        'rank_arr': rank_arr,\n",
    "        'params': params,\n",
    "        'K_train_arr': K_train_arr\n",
    "    }\n",
    "\n",
    "    # Saving the dictionary to a file using pickle\n",
    "    with open(f'./{data_directory}/data_nqubits_{n_qubits}.pkl', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "\n",
    "    # import pickle\n",
    "\n",
    "    # # Loading the data from the pickle file\n",
    "    # with open(f'data_nqubits_{n_qubits}.pkl', 'rb') as f:\n",
    "    #     loaded_data = pickle.load(f)\n",
    "\n",
    "    # # Access the arrays after loading\n",
    "    # mse_arr = loaded_data['mse_arr']\n",
    "    # mse_arr_train = loaded_data['mse_arr_train']\n",
    "    # eig_vals_arr = loaded_data['eig_vals_arr']\n",
    "    # cond_no_arr = loaded_data['cond_no_arr']\n",
    "    # rank_arr = loaded_data['rank_arr']\n",
    "    # params = loaded_data['params']\n",
    "    # K_train_arr = loaded_data['K_train_arr']\n",
    "\n",
    "\n",
    "    mse_arr = np.array(mse_arr)\n",
    "    mse_mean = np.mean(mse_arr, axis=0, dtype=np.float64)\n",
    "    mse_std = np.std(mse_arr, axis=0) / np.log(10)\n",
    "\n",
    "    mse_mean_train = np.mean(mse_arr_train, axis=0)\n",
    "    mse_std_train = np.std(mse_arr_train, axis=0)\n",
    "\n",
    "    # save all files -------------------------------------------------------------------\n",
    "    np.savetxt(f\"./{data_directory}/mse_mean_nqubits_{n_qubits}_MNIST_Fashion\", [mse_mean], newline='')\n",
    "    np.savetxt(f\"./{data_directory}/mse_std_nqubits_{n_qubits}_MNIST_Fashion\", [mse_std], newline='')\n",
    "    np.savetxt(f\"./{data_directory}/mse_mean_train_nqubits_{n_qubits}_MNIST_Fashion\", [mse_mean_train], newline='')\n",
    "    np.savetxt(f\"./{data_directory}/mse_std_train_nqubits_{n_qubits}_MNIST_Fashion\", [mse_std_train], newline='')\n",
    "    np.savetxt(f\"./{data_directory}/arrange_nqubits_{n_qubits}_MNIST_Fashion\", [np.arange(limit_low, limit_up, step)], newline='')\n",
    "    np.savetxt(f\"./{data_directory}/rank_arr_nqubits_{n_qubits}MNIST_Fashion\", [rank_arr], newline='')\n",
    "    np.savetxt(f\"./{data_directory}/cond_no_arr_nqubits_{n_qubits}MNIST_Fashion\", [cond_no_arr], newline='')\n",
    "\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Plotting Test MSE\n",
    "    scenario = f\"MNIST_Fashion_nqubits_{n_qubits}\"\n",
    "    plt.plot(np.arange(limit_low, limit_up, step)/4**n_qubits, mse_mean, label=f\"max at {range(limit_low, limit_up, step)[np.argmax(mse_mean)]/4**n_qubits}\", marker=\"\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Number of training samples/4**n\")\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "    plt.savefig(f\"./{graph_directory}/{scenario}_MSE.png\", dpi=500, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting condition number of kernel matrix\n",
    "    plt.plot(np.arange(limit_low, limit_up, step)/4**n_qubits, cond_no_arr, label=f\"max at {range(limit_low, limit_up, step)[np.argmax(cond_no_arr)]/4**n_qubits}\", marker=\"*\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Number of training samples/4**n\")\n",
    "    plt.ylabel(\"Condition number of X\")\n",
    "    plt.savefig(f\"./{graph_directory}/{scenario}_cond_no_arr.png\", dpi=500, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting Rank  of kernel matrix\n",
    "    plt.plot(np.arange(limit_low, limit_up, step), rank_arr, label=\"rank of X\", marker=\"o\")\n",
    "    plt.axvline(range(limit_low, limit_up, step)[np.min(np.where(np.array(rank_arr) == np.max(np.array(rank_arr))))], label=f\"min(max rank) = {range(limit_low, limit_up, step)[np.min(np.where(np.array(rank_arr) == np.max(np.array(rank_arr))))]}\", color=\"black\")\n",
    "    plt.axhline(no_train, color=\"grey\", label=\"dim. feature space\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Number of training samples/4**n\")\n",
    "    plt.ylabel(\"Rank of X\")\n",
    "    plt.savefig(f\"./{graph_directory}/{scenario}_rank_arr.png\", dpi=500, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    rank = np.linalg.matrix_rank(X)\n",
    "    print(rank, \"/ \", no_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codecraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
